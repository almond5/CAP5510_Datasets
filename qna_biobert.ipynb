{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.45.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: filelock in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: torch in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: filelock in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.26.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.15.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "%pip install torch\n",
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"qiaojin/PubMedQA\", \"pqa_labeled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "Map: 100%|██████████| 10/10 [00:00<00:00, 209.86 examples/s]\n",
      "  4%|▍         | 7/180 [10:52<4:28:48, 93.23s/it]\n",
      " 33%|███▎      | 6/18 [00:11<00:21,  1.78s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                               \n",
      " 33%|███▎      | 6/18 [00:12<00:21,  1.78s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2338898181915283, 'eval_runtime': 0.683, 'eval_samples_per_second': 2.928, 'eval_steps_per_second': 2.928, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 12/18 [00:22<00:10,  1.68s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                               \n",
      " 67%|██████▋   | 12/18 [00:22<00:10,  1.68s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3380873203277588, 'eval_runtime': 0.6236, 'eval_samples_per_second': 3.207, 'eval_steps_per_second': 3.207, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:32<00:00,  1.62s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                       \n",
      "                                               \n",
      "100%|██████████| 18/18 [00:34<00:00,  1.62s/it]\n",
      "\u001b[A\n",
      "100%|██████████| 18/18 [00:34<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3831374645233154, 'eval_runtime': 0.6, 'eval_samples_per_second': 3.333, 'eval_steps_per_second': 3.333, 'epoch': 3.0}\n",
      "{'train_runtime': 34.3542, 'train_samples_per_second': 0.524, 'train_steps_per_second': 0.524, 'train_loss': 1.1432906256781683, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation: {'eval_loss': 1.0763216018676758, 'eval_runtime': 0.6505, 'eval_samples_per_second': 3.074, 'eval_steps_per_second': 3.074, 'epoch': 3.0}\n",
      "Question: Syncope during bathing in infants, a pediatric form of water-induced urticaria?\n",
      "Context: {'contexts': ['Apparent life-threatening events in infants are a difficult and frequent problem in pediatric practice. The prognosis is uncertain because of risk of sudden infant death syndrome.', 'Eight infants aged 2 to 15 months were admitted during a period of 6 years; they suffered from similar maladies in the bath: on immersion, they became pale, hypotonic, still and unreactive; recovery took a few seconds after withdrawal from the bath and stimulation. Two diagnoses were initially considered: seizure or gastroesophageal reflux but this was doubtful. The hypothesis of an equivalent of aquagenic urticaria was then considered; as for patients with this disease, each infant\\'s family contained members suffering from dermographism, maladies or eruption after exposure to water or sun. All six infants had dermographism. We found an increase in blood histamine levels after a trial bath in the two infants tested. The evolution of these \"aquagenic maladies\" was favourable after a few weeks without baths. After a 2-7 year follow-up, three out of seven infants continue to suffer from troubles associated with sun or water.'], 'labels': ['BACKGROUND', 'CASE REPORTS'], 'meshes': ['Baths', 'Histamine', 'Humans', 'Infant', 'Syncope', 'Urticaria', 'Water'], 'reasoning_required_pred': ['y', 'e', 's'], 'reasoning_free_pred': ['y', 'e', 's']}\n",
      "True Answer: yes\n",
      "Predicted Answer: maybe\n",
      "================================================================================\n",
      "Question: Can tailored interventions increase mammography use among HMO women?\n",
      "Context: {'contexts': ['Telephone counseling and tailored print communications have emerged as promising methods for promoting mammography screening. However, there has been little research testing, within the same randomized field trial, of the efficacy of these two methods compared to a high-quality usual care system for enhancing screening. This study addressed the question: Compared to usual care, is tailored telephone counseling more effective than tailored print materials for promoting mammography screening?', 'Three-year randomized field trial.', 'One thousand ninety-nine women aged 50 and older recruited from a health maintenance organization in North Carolina.', 'Women were randomized to 1 of 3 groups: (1) usual care, (2) tailored print communications, and (3) tailored telephone counseling.', 'Adherence to mammography screening based on self-reports obtained during 1995, 1996, and 1997.', 'Compared to usual care alone, telephone counseling promoted a significantly higher proportion of women having mammograms on schedule (71% vs 61%) than did tailored print (67% vs 61%) but only after the first year of intervention (during 1996). Furthermore, compared to usual care, telephone counseling was more effective than tailored print materials at promoting being on schedule with screening during 1996 and 1997 among women who were off-schedule during the previous year.'], 'labels': ['BACKGROUND', 'DESIGN', 'PARTICIPANTS', 'INTERVENTION', 'MAIN OUTCOME', 'RESULTS'], 'meshes': ['Cost-Benefit Analysis', 'Female', 'Health Maintenance Organizations', 'Humans', 'Logistic Models', 'Mammography', 'Marketing of Health Services', 'Middle Aged', 'North Carolina', 'Odds Ratio', 'Pamphlets', 'Patient Acceptance of Health Care', 'Patient Satisfaction', 'Reminder Systems', 'Telephone'], 'reasoning_required_pred': ['y', 'e', 's'], 'reasoning_free_pred': ['n', 'o']}\n",
      "True Answer: yes\n",
      "Predicted Answer: maybe\n",
      "================================================================================\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load BioBERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\", num_labels=3)  # 3 for yes/no/maybe classification\n",
    "\n",
    "# Move model to the available device (cuda or cpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Load the dataset\n",
    "ds = load_dataset(\"qiaojin/PubMedQA\", \"pqa_labeled\")\n",
    "\n",
    "# Preprocess the dataset\n",
    "def preprocess_function(examples):\n",
    "    inputs = examples['question']\n",
    "    # Use context for more accurate predictions\n",
    "    context = examples['context']\n",
    "    # Extract the true answers\n",
    "    targets = examples['final_decision']\n",
    "    \n",
    "    # Combine question and context\n",
    "    combined_input = [f\"Context: {c} Question: {q}\" for q, c in zip(inputs, context)]\n",
    "    \n",
    "    # Tokenize the inputs and labels\n",
    "    model_inputs = tokenizer(combined_input, max_length=512, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    # Map the final_decision (yes/no/maybe) to labels\n",
    "    label_map = {\"yes\": 0, \"no\": 1, \"maybe\": 2}\n",
    "    labels = [label_map[ans] for ans in targets]\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels\n",
    "\n",
    "    return model_inputs\n",
    "\n",
    "# Select a small subset of the dataset for demonstration\n",
    "small_ds = ds['train'].select(range(50))\n",
    "tokenized_ds = small_ds.map(preprocess_function, batched=True)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_size = 30\n",
    "val_size = 10\n",
    "test_size = 10\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    tokenized_ds, [train_size, val_size, test_size]\n",
    ")\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "metrics = trainer.evaluate(eval_dataset=test_dataset)\n",
    "print(\"Test set evaluation:\", metrics)\n",
    "\n",
    "# Generate predictions\n",
    "def prediction_answer(question, context):\n",
    "    # Combine the question and context into one input\n",
    "    combined_input = f\"Context: {context} Question: {question}\"\n",
    "    \n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(combined_input, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}  # Move inputs to the correct device\n",
    "    \n",
    "    # Get the model's output\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_label = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    # Map numeric labels to \"yes\", \"no\", or \"maybe\"\n",
    "    label_map = {0: \"yes\", 1: \"no\", 2: \"maybe\"}\n",
    "    return label_map[predicted_label]\n",
    "\n",
    "num_correct = 0\n",
    "\n",
    "# Evaluate the Q&A performance\n",
    "for example in test_dataset:\n",
    "    question = example['question']\n",
    "    # Include the context field in the prediction\n",
    "    context = example['context']\n",
    "    # Extract true answer from 'final_decision' column\n",
    "    true_answer = example['final_decision']\n",
    "    # Use model to predict the answer\n",
    "    predicted_answer = prediction_answer(question, context)\n",
    "    \n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Context: {context}\")\n",
    "    print(f\"True Answer: {true_answer}\")\n",
    "    print(f\"Predicted Answer: {predicted_answer}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    if true_answer == predicted_answer:\n",
    "        num_correct += 1\n",
    "\n",
    "# Print accuracy\n",
    "accuracy = num_correct / len(test_dataset)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
